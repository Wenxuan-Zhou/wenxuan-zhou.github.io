<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Wenxuan Zhou</title>
  
  <meta name="author" content="Wenxuan Zhou">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Wenxuan Zhou</name>
              </p>
              <p>I am a Ph.D. student at the Robotics Institute (RI) at Carnegie Mellon University,
                advised by <a href="https://davheld.github.io/">Prof. David Held</a>.
                My research goal is to enable task-level autonomy for robots through data-driven approaches
                such as reinforcement learning.
                I will be joining <a href="https://deepmind.com/">DeepMind</a> as an intern in Summer 2021.
              </p>
              <p>I received my master's degree at RI mentored by <a href="https://cs.nyu.edu/~lp91/">Lerrel Pinto</a>
                and advised by <a href="http://www.cs.cmu.edu/~abhinavg/">Prof. Abhinav Gupta</a>.
                During my undergraduate study, I worked with <a href="http://www-personal.umich.edu/~orosz/">Prof. Gabor Orosz</a>
                on ground robot experiments with connected cruise control.
                I've also interned at ZF TRW at the brake control systems group.</p>

              <p style="text-align:center">
                <a href="https://www.cs.cmu.edu/directory/wenxuanz">Contact</a> &nbsp/&nbsp
                <a href="https://github.com/Wenxuan-Zhou">GitHub</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=picvdvEAAAAJ&hl=en&oi=ao">Google Scholar</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/Wenxuan-circle.png" class="hoverZoomLink">
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

           <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/LP.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <papertitle>PLAS: Latent Action Space for Offline Reinforcement Learning</papertitle><br>
              <strong>Wenxuan Zhou</strong>, <a href="https://sujaybajracharya.me/">Sujay Bajracharya</a>, <a href="http://davheld.github.io/">David Held</a><br>
              <em>CoRL 2020 (Plenary Talk)</em><br>
              <p>Learning policy in the latent action space to naturally avoid out-of-distribution actions.</p>
              <p>#Offline_RL #Off_Policy_RL #Cloth_Manipulation</p>
              <a href="https://drive.google.com/file/d/1zmL1sLnEqFv2lSNqdqJpjE8V7gUtaOMa/view">[Paper]</a>
              <a href="https://github.com/Wenxuan-Zhou/PLAS">[Code]</a>
              <a href="https://sites.google.com/view/latent-policy">[Website]</a><br>
            </td>
          </tr>

           <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/LBPO.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Lyapunov Barrier Policy Optimization</papertitle><br>
              <a href="https://hari-sikchi.github.io/">Harshit Sikchi</a>, <strong>Wenxuan Zhou</strong>, <a href="http://davheld.github.io/">David Held</a><br>
              <em>In submission</em>
              <p>#Safe_RL</p>
            </td>
          </tr>

           <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/LOOP.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Learning Off-Policy with Online Planning</papertitle>
              <br>
              <a href="https://hari-sikchi.github.io/">Harshit Sikchi</a>, <strong>Wenxuan Zhou</strong>, <a href="http://davheld.github.io/">David Held</a>
              <br>
              <em>ICML 2020 Workshop on Inductive Biases, Invariances and Generalization in RL</em>
              <p> Enhancing model-based CEM with a terminal Q-function learned by an off-policy algorithm.</p>
              <p>#Model_Based_RL #Model_Free_RL</p>
              <a href="https://biases-invariances-generalization.github.io/pdf/big_47.pdf">[Paper]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/EPI.gif" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <papertitle>EPI: Environment Probing Interaction Policies</papertitle>
              <br>
              <strong>Wenxuan Zhou</strong>, <a href="https://cs.nyu.edu/~lp91/">Lerrel Pinto</a>, <a href="http://www.cs.cmu.edu/~abhinavg/">Abhinav Gupta</a><br>
              <em>ICLR 2019</em><br>
              <p>Learning to "probe" the environment before task execution.</p>
              <p>#System_Identification  #Environment_Generalization  #Multi_Task_Learning</p>
              <a href="https://openreview.net/pdf?id=ryl8-3AcFX">[Paper]</a><a href="https://github.com/Wenxuan-Zhou/EPI">[Code]</a>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://github.com/jonbarron/website">Source</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
