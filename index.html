<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Wenxuan Zhou</title>
  
  <meta name="author" content="Wenxuan Zhou">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Wenxuan Zhou</name>
              </p>
              <p>I am a Ph.D. student at the Robotics Institute (RI) at Carnegie Mellon University,
                advised by <a href="https://davheld.github.io/">Prof. David Held</a>. My thesis research has been focused on enabling robot to perform complex interactions using reinforcement learning. I am broadly interested in sequential decision-making problems in AI and robotics. 
              </p>
              <p> During Summer 2023, I interned at Google DeepMind Robotics working with <a href="https://keerthanapg.com/">Keerthana Gopalakrishnan</a> on imitation learning from human videos. In 2022, I worked at FAIR as a visiting researcher with <a href="https://cpaxton.github.io/about/">Chris Paxton</a>. We worked on RL with point cloud observations and contact-rich manipulation.
                During Summer 2021, I interned at DeepMind mentored by Steven Bohez and studied the problems of RL under non-stationary dynamics.
              </p>
              <p>
                I received my master's degree at RI mentored by <a href="https://cs.nyu.edu/~lp91/">Lerrel Pinto</a>
                and advised by <a href="http://www.cs.cmu.edu/~abhinavg/">Prof. Abhinav Gupta</a>.
                During my undergraduate study, I worked with <a href="http://www-personal.umich.edu/~orosz/">Prof. Gabor Orosz</a>
                on ground robots with connected cruise control.</p>
              <p><span style="color:#FF0000">I'm actively searching for full-time positions in AI and robotics!</span> Feel free to reach out at wenxuanz0413 -at- gmail.</p>
              <p style="text-align:center">
                <a href="https://github.com/Wenxuan-Zhou">GitHub</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=picvdvEAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/feed/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://twitter.com/Wenxuan_Zhou">Twitter</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/Wenxuan-circle.png" class="hoverZoomLink">
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/hacman.gif" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <papertitle>HACMan: Learning Hybrid Actor-Critic Maps for 6D Non-Prehensile Manipulation</papertitle>
              <br>
              <strong>Wenxuan Zhou</strong>, Bowen Jiang, Fan Yang, <a href="https://cpaxton.github.io/about/">Chris Paxton*</a>, <a href="http://davheld.github.io/">David Held*</a>
              <br>
              <em>Conference of Robot Learning 2023 <span style="color:#FF0000">(Oral)</span></em>
              <br>
              <p> We propose a spatially-grounded and temporally-abstracted action representation with a hybrid discrete-continuous reinforcement learning framework.</p>
              <p>Keywords: RL with 3D Vision, Action Representation, Contact-rich manipulation</p>
              <a href="https://arxiv.org/abs/2305.03942">[Paper]</a>
              <a href="https://github.com/HACMan-2023/HACMan">[Code]</a>
              <a href="https://hacman-2023.github.io/">[Website]</a>
              <br>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/og.gif" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Learning to Grasp the Ungraspable with Emergent Extrinsic Dexterity</papertitle>
              <br>
              <strong>Wenxuan Zhou</strong>, <a href="http://davheld.github.io/">David Held</a>
              <br>
              <em>Conference of Robot Learning 2022 <span style="color:#FF0000">(Oral)</span></em>
              <br>
              <em>ICRA 2022 Workshop on Reinforcement Learning for Contact-Rich Manipulation</em>
              <br>
              <em>Press Coverage: IEEE Specturm - <a href="https://spectrum.ieee.org/robot-gripper-extrinsic-dexterity">Robots Grip Better When They Grip Smarter</a></em>
              <p> We present a system that applies reinforcement learning to extrinsic dexterity that solves an occluded grasping task with a simple gripper.</p>
              <p>Keywords: Contact-rich manipulation, Sim2Real</p>
              <a href="https://arxiv.org/abs/2211.01500">[Paper]</a>
              <a href="https://github.com/Wenxuan-Zhou/ungraspable">[Code]</a>
              <a href="https://sites.google.com/view/grasp-ungraspable">[Website]</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/op3.gif" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Forgetting and Imbalance in Robot Lifelong Learning with Off-policy Data
              </papertitle>
              <br>
              <strong>Wenxuan Zhou</strong>, Steven Bohez, Jan Humplik, Abbas Abdolmaleki, Dushyant Rao, Markus Wulfmeier, Tuomas Haarnoja, Nicolas Heess
              <br>
              <em>Conference on Lifelong Learning Agents (CoLLAs) 2022</em>
              <br>
              <p> We identify two challenges in robot lifelong learning with non-stationary dynamics due to off-policy data.</p>
              <p>Keywords: Lifelong Learning, Offline RL, Off-Policy RL</p>
              <a href="https://arxiv.org/abs/2204.05893">[Paper]</a>
              <a href="https://virtual.lifelong-ml.cc/poster_61.html">[Website]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/loop-v2.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Learning Off-Policy with Online Planning</papertitle>
              <br>
              <a href="https://hari-sikchi.github.io/">Harshit Sikchi</a>, <strong>Wenxuan Zhou</strong>, <a href="http://davheld.github.io/">David Held</a>
              <br>
              <em>Conference of Robot Learning 2021 <span style="color:#FF0000">(Oral, Best Paper Finalist)</span></em>
              <p> A novel instantiation of H-step lookahead policies with a learned model and a terminal value from a model-free off-policy algorithm.</p>
              <p>Keywords: Model-Based RL, Model-Free RL</p>
              <a href="https://arxiv.org/abs/2008.10066">[Paper]</a>
              <a href="https://github.com/hari-sikchi/LOOP">[Code]</a>
              <a href="https://hari-sikchi.github.io/loop/">[Website]</a>
            </td>
          </tr>

           <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/LP.gif" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <papertitle>PLAS: Latent Action Space for Offline Reinforcement Learning</papertitle><br>
              <strong>Wenxuan Zhou</strong>, <a href="https://sujaybajracharya.me/">Sujay Bajracharya</a>, <a href="http://davheld.github.io/">David Held</a><br>
              <em>Conference of Robot Learning 2020 <span style="color:#FF0000">(Plenary Talk)</span></em><br>
              <p>Learning policy in the latent action space to naturally avoid out-of-distribution actions.</p>
              <p>Keywords: Offline RL, Off-Policy RL, Deformable Object Manipulation</p>
              <a href="https://arxiv.org/abs/2011.07213">[Paper]</a>
              <a href="https://github.com/Wenxuan-Zhou/PLAS">[Code]</a>
              <a href="https://sites.google.com/view/latent-policy">[Website]</a><br>
            </td>
          </tr>

           <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/LBPO.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Lyapunov Barrier Policy Optimization</papertitle><br>
              <a href="https://hari-sikchi.github.io/">Harshit Sikchi</a>, <strong>Wenxuan Zhou</strong>, <a href="http://davheld.github.io/">David Held</a><br>
              <em>NeurIPS Deep RL Workshop 2020</em><br>
              <p>Safe reinforcement learning with a Lyapunov-based barrier function.</p>
              <p>Keywords: Safe RL</p>
              <a href="https://arxiv.org/abs/2103.09230">[Paper]</a>
              <a href="https://github.com/hari-sikchi/LBPO">[Code]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/EPI.gif" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <papertitle>EPI: Environment Probing Interaction Policies</papertitle>
              <br>
              <strong>Wenxuan Zhou</strong>, <a href="https://cs.nyu.edu/~lp91/">Lerrel Pinto</a>, <a href="http://www.cs.cmu.edu/~abhinavg/">Abhinav Gupta</a><br>
              <em>ICLR 2019</em><br>
              <p>Learning to "probe" the environment before task execution.</p>
              <p>Keywords: System Identification, Multi-Task RL</p>
              <a href="https://openreview.net/pdf?id=ryl8-3AcFX">[Paper]</a><a href="https://github.com/Wenxuan-Zhou/EPI">[Code]</a>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Last update: Oct 2023
                <br>
                <a href="https://github.com/jonbarron/website">Source</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
